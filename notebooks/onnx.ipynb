{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "74134618-2220-4217-aa35-8f54b9ec665a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import onnxruntime as rt\n",
    "from scipy.special import softmax\n",
    "\n",
    "sess = rt.InferenceSession(\"/Users/james/playground/mario-gpt/notebooks/custom_onnx_output/model.onnx\")\n",
    "encoder_sess = rt.InferenceSession(\"/Users/james/playground/mario-gpt/notebooks/bert_base/encoder_model.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5a06d495-1d69-4d9f-9cde-5b85a442a6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1 2 3 4 5]]]\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[[1, 2, 3, 4, 5]]])\n",
    "print(a)\n",
    "print(a[0, 0, 2])\n",
    "b = a[:, -1, :].flatten()\n",
    "print(b[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "45d1c53b-11d8-4589-941e-43f43a9236f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids\n",
      "attention_mask\n",
      "position_ids\n",
      "encoder_hidden_states\n"
     ]
    }
   ],
   "source": [
    "for input in sess.get_inputs():\n",
    "    print(input.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3739e515-d8fc-4f4e-a4ee-05c81ccc2ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 768)\n"
     ]
    }
   ],
   "source": [
    "# Encode prompt\n",
    "import json\n",
    "vocab_path = \"/Users/james/playground/mario-gpt/notebooks/bart_base/bart_vocab.json\"\n",
    "f = open(vocab_path, 'r')\n",
    "vocab_data = json.load(f)\n",
    "f.close()\n",
    "\n",
    "def tokenize(text, vocab, max_seq_length):\n",
    "    tokens = text.split()  # Simple whitespace tokenizer\n",
    "    token_ids = [vocab.get(token, vocab['<unk>']) for token in tokens]\n",
    "\n",
    "    # Truncate if too long\n",
    "    if len(token_ids) > max_seq_length - 2:\n",
    "        token_ids = token_ids[:max_seq_length - 2]\n",
    "\n",
    "    # Add <s> and </s>\n",
    "    token_ids = [vocab['<s>']] + token_ids + [vocab['</s>']]\n",
    "    attention_mask = [1] * len(token_ids)\n",
    "\n",
    "    return np.array(token_ids), np.array(attention_mask)\n",
    "\n",
    "prompt = \"many pipes, many enemies, some blocks, high elevation\"\n",
    "token_ids, attention_mask = tokenize(prompt, vocab_data, 1024)\n",
    "token_ids = token_ids.reshape(1, token_ids.shape[0])\n",
    "attention_mask = attention_mask.reshape(1, attention_mask.shape[0])\n",
    "\n",
    "encoded = encoder_sess.run(None, {'input_ids': token_ids, 'attention_mask': attention_mask})\n",
    "hidden = encoded[0].mean(1).reshape(1, 1, encoded[0].shape[-1])\n",
    "print(hidden.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "293bbc9b-3cf2-4edb-ab62-113ca9e3b11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[56 56 88 13 13 79 79 13 13 13 13 13 13 13 13 88 88 13 13 13 79 13 13 13\n",
      "  13 13 13 13 13 13 88 88 13 13 13 13 13 13 13 13 13 13 13 13 13 88 88 13\n",
      "  13 13 13 13 13 13 13 13 13 13 13 13 88 79 79 13 13 13 13 13 13 13 13 13\n",
      "  13 13 88 79 79 13 13 13 13 13 13 13 13 13 13 13 88 79 79 13 13 13 13 13\n",
      "  13 13 13 13 13 13 88 13 13 13 13 13 13 13 13 13 13 13 13 88 13 13 13 13\n",
      "  13 13 13 13 13 13 56 56 88 13 13 13 13 13 37 13 13 13 13 13 56 56 88 88\n",
      "  13 13 13 13 13 13 13 13 13 13 56 56 56 88 88 13 13 13 13 13 13 13 13 13\n",
      "  56 56 56 56 88 88 13 13 13 13 13 13 13 13 56 56 56 13 13 88 88 13 13 13\n",
      "  13 13 13 13 56 59 59 59 28 88 13 13 13 13 13 13 13 13 56 61 61 61 30 88\n",
      "  13 13 13 13 13 13 13 13 56 56 56 56 56 88 88 79 13 13 13 13 13 13 13 13\n",
      "  13 13 13 13 88 56 13 13 13 13 13 13 13 13 13 13 13 13 88 79 13 13 13 13\n",
      "  13 13 13 13 13 13 13 13 88 79 13 13 13 13 13 13 56 59 59 59 28 88 13 13\n",
      "  13 13 13 13 13 13 56 61 61 61 30 88 13 13 13 13 13 13 13 13 56 56 56 56\n",
      "  13 88 13 13 13 13 13 13 13 13 56 56 56 56 88 13 13 13 13 13 13 13 13 13\n",
      "  56 13 13 13 88 13 13 13 13 13 13 13 13 13 56 13 13 88 13 13 13 13 13 13\n",
      "  13 13 13 13 13 13 88 13 13 13 13 13 13 13 13 13 13 13 56 88 13 13 13 13\n",
      "  13 13 13 13 13 13 13 13 56 88 13 13 13 13 13 13 13 13 13 13 13 13 56 88\n",
      "  13 13 13 13 13 13 13 13 13 13 13 13 56 88 13 13 13 13 13 13 13 13 13 13\n",
      "  13 13 56 88 88 13 13 13 13 13 13 13 13 13 13 13 56 56 88 88 13 13 13 13\n",
      "  13 13 13 13 13 13 56 56 56 88 88 13 13 13 13 13 13 13 13 13 56 56 56 56\n",
      "  88 88 13 13 13 13 13 13 13 13 56 56 56 56 56 88 88 13 13 13 13 13 13 13\n",
      "  56 56 56 56 56 56 88 13 13 13 13 13 13 13 13 56 56 56 56 51 88 13 13 13\n",
      "  13 13 13 13 13 13 13 13 13 51 88 88 13 13 13 13 13 13 13 13 13 13 13 13\n",
      "  51 88 13 13 13 13 13 13 13 51 13 13 13 51 13 88 13 13 13 13 13 13 13 51\n",
      "  13 13 13 49 88 88 13 13 13 13 13 13 13 51 13 13 13 13 13 88 13 13 13 13\n",
      "  13 13 13 51 13 13 13 13 13 88 13 13 13 13 13 13 13 51 13 13 13 13 88 13\n",
      "  13 13 13 13 13 13 13 51 13 13 13 88 79 13 13 13 13 13 13 13 13 51 13 13\n",
      "  88 13 79 13 13 13 13 13 13 13 13 51 13 88 13 13 13 13 13 13 13 13 13 13\n",
      "  56 13 88 13 13 13 13 13 13 13 13 13 13 13 56 88 13 13 13 13 13 13 13 13\n",
      "  13 13 13 13 88]]\n"
     ]
    }
   ],
   "source": [
    "# Generate seed and run iterations\n",
    "seed = np.array([[56]])\n",
    "out = seed\n",
    "num_steps = 700\n",
    "context_len = 700-28\n",
    "for i in range(num_steps):\n",
    "    inp_ids = out * 1\n",
    "    if len(out.shape) > 0 and out.shape[-1] > context_len:\n",
    "        diff = inp_ids.shape[-1] % 14  # height of mario level\n",
    "        ctx = context_len + diff\n",
    "        inp_ids = inp_ids[:, -ctx:] * 1\n",
    "    n_vals = inp_ids.shape[-1]\n",
    "    position_ids = (np.arange(n_vals)).reshape(1, n_vals)\n",
    "    attention_mask = np.ones((1, n_vals), dtype=np.int64)\n",
    "    preds = sess.run(None, {\"input_ids\": inp_ids, \"position_ids\": position_ids, \"attention_mask\": attention_mask, 'encoder_hidden_states': hidden})\n",
    "    logits = preds[0]\n",
    "    logits = logits[:, -1, :].flatten()\n",
    "    k = 16\n",
    "    indices_of_top_k = np.argpartition(logits, -k)[-k:]\n",
    "    indices_to_zero = np.setdiff1d(np.arange(logits.size), indices_of_top_k)\n",
    "    logits[indices_to_zero] = -np.inf\n",
    "    logits = logits / 2.0\n",
    "    probs = softmax(logits)\n",
    "    next = np.array([[np.random.choice(len(probs), p=probs)]])\n",
    "    \n",
    "    out = np.concatenate([out, next.reshape([1, 1])], axis=-1)\n",
    "\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "39f42a4c-4b92-4741-8ea5-ad96610a554e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "---------E----------------------------------------\n",
      "----------------oXoo------------------xxxxxx------\n",
      "oo--ooo------x--xxxx---------------xxxxS-x--xoo---\n",
      "o---ooo-----xxxxx---xxx-----------xxXSS-SQ---x----\n",
      "---xxxxx---xx-<>X---<>-xx--------xxXXX--------x---\n",
      "--xx----x-xxX-[]X---[]XX-x------xxXXXX---------x--\n",
      "xxx------xxXXX[]X---[]XX--x----xxXXXXX----------x-\n",
      "Xx-------XXXXX[]X---[]XX---xxxxxXXXXXX--SSSSSSSS-x\n",
      "X--------XXXXXXXX---XXXXXX-XXXXXXXXXX-----------XX\n"
     ]
    }
   ],
   "source": [
    "# Parse the map\n",
    "import json\n",
    "tok_path = \"/Users/james/playground/mario-gpt/notebooks/Mario-GPT2-700-context-length/onnx_output/tokenizer.json\"\n",
    "f = open(tok_path, 'r')\n",
    "data = json.load(f)\n",
    "f.close()\n",
    "tokenizer = {}\n",
    "for c, i in data['model']['vocab'].items():\n",
    "    tokenizer[i] = c\n",
    "    \n",
    "str_list = []\n",
    "for i in range(out.shape[1]):\n",
    "    str_list.append(tokenizer[out[0, i]])\n",
    "\n",
    "n_cols = len(str_list) // 14\n",
    "cols = []\n",
    "col = []\n",
    "for i, c in enumerate(str_list):\n",
    "    if i > 0 and i % 14 == 0:\n",
    "        cols.append(\"\".join(col))\n",
    "        col = []\n",
    "    col.append(c)\n",
    "\n",
    "rows = []\n",
    "for i in reversed(range(14)):\n",
    "    row = []\n",
    "    for j in range(n_cols):\n",
    "        row.append(cols[j][i])\n",
    "    rows.append(\"\".join(row))\n",
    "map = \"\\n\".join(rows)\n",
    "\n",
    "print(map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee6e6d8-6c22-4fa8-93c6-2d93bdd1e663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f35e8b-b264-4b42-a4e8-06ee0c3fd3ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede09d20-0f24-4ad5-b29b-764ecdaf0790",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
